{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSI 4142 Data Science \n",
    "## Assignment 2 - Data Cleaning\n",
    "\n",
    "### Identification\n",
    "\n",
    "Name: Eli Wynn<br/>\n",
    "Student Number: 300248135\n",
    "\n",
    "Name: Jack Snelgrove<br/>\n",
    "Student Number: 300247435\n",
    "\n",
    "\n",
    "Our datasets have been uploaded from the public repository:\n",
    "\n",
    "- [github.com/eli-wynn/Datasets](https://github.com/eli-wynn/Datasets)\n",
    "\n",
    "Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix  = \"https://raw.githubusercontent.com/eli-wynn/Datasets/refs/heads/main/netflix_titles.csv\"\n",
    "netflixData = pd.read_csv(netflix)\n",
    "startup = \"https://raw.githubusercontent.com/eli-wynn/Datasets/refs/heads/main/startup.csv\"\n",
    "startupData = pd.read_csv(startup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Data Checker\n",
    "\n",
    "#### Data Type Error\n",
    "\n",
    "A data type error occurs when the the data entered into a column doesnt match the data type assigned to that column. There are zero datatype errors in the Netflix dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intCol = ['release_year']\n",
    "stringCols = ['show_id', 'type', 'title', 'director', 'cast', 'country', 'rating', 'duration', 'listed_in', 'description']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checker Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in intCol:\n",
    "    netflixData[col] = pd.to_numeric(netflixData[col], errors='coerce')\n",
    "\n",
    "for col in stringCols:\n",
    "    invalid_strings = netflixData[~netflixData[col].astype(str).apply(lambda x: isinstance(x, str))]\n",
    "    if not invalid_strings.empty:\n",
    "        print(f\"\\nPossible non-string values in '{col}':\\n\", invalid_strings.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find rows where conversion resulted in NaN (potential type errors)\n",
    "type_errors = netflixData[netflixData[intCol].isna().any(axis=1)]\n",
    "print(\"Possible data type errors:\\n\", type_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Range Errors\n",
    "\n",
    "Searches for errors where the data is outside acceptable range (e.g. season -1 or release date prior to 1930)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "releaseParam = [1925, 2025]\n",
    "durationParams = [0, 300] #split on space and make sure first item in array is >0 <300\n",
    "dateAdded = [2007, 2025] #just look at year "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checker Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "releaseErrors = netflixData[(netflixData['release_year'] < releaseParam[0]) | (netflixData['release_year'] > releaseParam[1])]\n",
    "\n",
    "netflixData['duration_split'] = netflixData['duration'].str.split(\" \").str[0]  # Extract number part\n",
    "netflixData['duration_split'] = pd.to_numeric(netflixData['duration_split'], errors='coerce')  # Convert to int\n",
    "# Identify invalid durations\n",
    "durationErrors = netflixData[(netflixData['duration_split'] <= durationParams[0]) | (netflixData['duration_split'] >= durationParams[1])]\n",
    "\n",
    "netflixData['date_added'] = pd.to_datetime(netflixData['date_added'], errors='coerce')\n",
    "netflixData['year_added'] = netflixData['date_added'].dt.year #take just year value, other date errors will be caught in format error below\n",
    "# Identify invalid date_added values\n",
    "dateAddedErrors = netflixData[(netflixData['year_added'] < dateAdded[0]) | (netflixData['year_added'] > dateAdded[1])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Findings\n",
    "\n",
    "Only one duration error, a black mirror episode longer than 300 minutes, don't know whether it is just an abnormally long episode outside my set parameters or needs to be cleaned up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nRelease Year Errors:\\n\", releaseErrors[['title', 'release_year']].head(5))\n",
    "print(\"\\nDuration Errors:\\n\", durationErrors[['show_id', 'title', 'duration', 'duration_split']].head(5))\n",
    "print(\"\\nDate Added Errors:\\n\", dateAddedErrors[['title', 'date_added', 'year_added']].head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Format Errors\n",
    "\n",
    "Checks for errors with the formatting of the data, e.g. date being DD-MM-YYYY instead of YYYY first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dateCol = ['date_added'] #make sure date is correct format\n",
    "showCol = ['show_id'] #make sure it is s### format\n",
    "durationCol = ['duration'] #make sure duration is number followed by either \"min\" or \"Season\" or \"Seasons\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checker Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in dateCol:\n",
    "    netflixData[col] = pd.to_datetime(netflixData[col], errors='coerce')\n",
    "invalid_dates = netflixData[netflixData[dateCol].isna().any(axis=1)]\n",
    "\n",
    "brokenID = netflixData[~netflixData['show_id'].astype(str).str.match(r\"^s\\d{1,4}$\", na=False)] #finds all ids that don't match format of s followed by 1-4 #'s\n",
    "brokenDuration = netflixData[~netflixData['duration'].astype(str).str.match(r\"^\\d+\\s(min|Season|Seasons)$\", na=False)] #finds all id's that don't match digits then space then seasons, season or min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Findings\n",
    "\n",
    "Louis C.K. titles have the durations in the ratings column for some reason - formatting is technically correct though\n",
    "<br> No show ID errors\n",
    "<br> There are a few date formatting errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nPossible date format errors:\\n\", invalid_dates[['title', 'date_added']].head(5))\n",
    "print(\"\\nShow ID Format Errors:\\n\", brokenID[['show_id', 'title']].head(5))\n",
    "print(\"\\nDuration Format Errors:\\n\", brokenDuration[['duration', 'title']].head(5)) #Louis C.k. durations are in rating column for some reason"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Consistency Errors\n",
    "\n",
    "a type of logical check that ensures data is entered in a\n",
    "logically consistent manner. In this data a consistensy error could be checking that movies all have their duration in minutes and shows in seasons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters changed below by updating movie or tv show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checker Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movieErr = netflixData[(netflixData['type'] == 'Movie')&~netflixData['duration'].astype(str).str.match(r\"^\\d+\\smin$\", na=False)]\n",
    "tvErr = netflixData[(netflixData['type'] == 'TV Show')&~netflixData['duration'].astype(str).str.match(r\"^\\d+\\s(Season|Seasons)$\", na=False)] #match all tv show types and regex to ensure consistent season/seasons format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Findings\n",
    "\n",
    "No errors in the consistency just the same duration absences discovered above in the louis C.K. stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nIncosistent Movie Durations: \\n\", movieErr[['title', 'type', 'duration']].head(5))\n",
    "print(\"\\nIncosistent Show Durations: \\n\", tvErr[['title', 'type', 'duration']].head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uniqueness Errors\n",
    "\n",
    "Ensure that there are no duplicate values, The title column is the only applicable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniquenessParams = ['show_id', 'title', 'release_year']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checker Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dupeShowID = netflixData[netflixData.duplicated(subset=[uniquenessParams[0]], keep=False)] #showID duplicate\n",
    "\n",
    "#Checking for duplicate titles isn't valid because two movies can have the same names so need to compare with release year as well\n",
    "dupeTitle = netflixData[netflixData.duplicated(subset=[uniquenessParams[1], uniquenessParams[2]], keep=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nDuplicate Show IDs: \\n\", dupeShowID[[uniquenessParams[0]].head(5)])\n",
    "print(\"\\nDuplicate titles: \\n\", dupeTitle[[uniquenessParams[1], uniquenessParams[2]].head(5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Presence Errors\n",
    "\n",
    "A presence error is when a mandatory value is left blank, in this case you could argue that every column is necessary but title, id and type are the most important"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mandatoryVals = ['show_id', 'title', 'release_year', 'type', 'duration']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checker Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missingValues = netflixData[netflixData[[mandatoryVals[0], mandatoryVals[1], mandatoryVals[2], mandatoryVals[3], mandatoryVals[4]]].isnull().any(axis=1)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nMissing mandatory values: \\n\", missingValues[['show_id', 'title', \n",
    "                                                'release_year', 'type', 'duration']].head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Length Errors\n",
    "\n",
    "Errors in which the length of a parameter is different then the norm. e.g. A title that is 2000 characters long is very likely a length error and an incorrectly input piece of data because 2000 characters is unreasonable to say"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titleSizeParam = [1,200]\n",
    "relYearParam = [4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checker Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titleLen = netflixData[(netflixData['title'].str.len() < titleSizeParam[0]) | (netflixData['title'].str.len() > titleSizeParam[1])]\n",
    "relYearLen = netflixData[(netflixData['release_year'].str.len() == releaseParam[0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nErroneous Title Lengths: \\n\", titleLen['title', 'show_id'].head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lookup Errors\n",
    "\n",
    "Errors which are caused by a value being outside the correct set of values. For example, having a made up month in a month of release. In this dataset lookup errors can be present in the country value, rating or type columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Country dictionary sourced from: https://stackoverflow.com/questions/41245330/check-if-a-country-entered-is-one-of-the-countries-of-the-world\n",
    "Country = [\n",
    "    ('US', 'United States'),\n",
    "    ('AF', 'Afghanistan'),\n",
    "    ('AL', 'Albania'),\n",
    "    ('DZ', 'Algeria'),\n",
    "    ('AS', 'American Samoa'),\n",
    "    ('AD', 'Andorra'),\n",
    "    ('AO', 'Angola'),\n",
    "    ('AI', 'Anguilla'),\n",
    "    ('AQ', 'Antarctica'),\n",
    "    ('AG', 'Antigua And Barbuda'),\n",
    "    ('AR', 'Argentina'),\n",
    "    ('AM', 'Armenia'),\n",
    "    ('AW', 'Aruba'),\n",
    "    ('AU', 'Australia'),\n",
    "    ('AT', 'Austria'),\n",
    "    ('AZ', 'Azerbaijan'),\n",
    "    ('BS', 'Bahamas'),\n",
    "    ('BH', 'Bahrain'),\n",
    "    ('BD', 'Bangladesh'),\n",
    "    ('BB', 'Barbados'),\n",
    "    ('BY', 'Belarus'),\n",
    "    ('BE', 'Belgium'),\n",
    "    ('BZ', 'Belize'),\n",
    "    ('BJ', 'Benin'),\n",
    "    ('BM', 'Bermuda'),\n",
    "    ('BT', 'Bhutan'),\n",
    "    ('BO', 'Bolivia'),\n",
    "    ('BA', 'Bosnia And Herzegowina'),\n",
    "    ('BW', 'Botswana'),\n",
    "    ('BV', 'Bouvet Island'),\n",
    "    ('BR', 'Brazil'),\n",
    "    ('BN', 'Brunei Darussalam'),\n",
    "    ('BG', 'Bulgaria'),\n",
    "    ('BF', 'Burkina Faso'),\n",
    "    ('BI', 'Burundi'),\n",
    "    ('KH', 'Cambodia'),\n",
    "    ('CM', 'Cameroon'),\n",
    "    ('CA', 'Canada'),\n",
    "    ('CV', 'Cape Verde'),\n",
    "    ('KY', 'Cayman Islands'),\n",
    "    ('CF', 'Central African Rep'),\n",
    "    ('TD', 'Chad'),\n",
    "    ('CL', 'Chile'),\n",
    "    ('CN', 'China'),\n",
    "    ('CX', 'Christmas Island'),\n",
    "    ('CC', 'Cocos Islands'),\n",
    "    ('CO', 'Colombia'),\n",
    "    ('KM', 'Comoros'),\n",
    "    ('CG', 'Congo'),\n",
    "    ('CK', 'Cook Islands'),\n",
    "    ('CR', 'Costa Rica'),\n",
    "    ('CI', 'Cote D`ivoire'),\n",
    "    ('HR', 'Croatia'),\n",
    "    ('CU', 'Cuba'),\n",
    "    ('CY', 'Cyprus'),\n",
    "    ('CZ', 'Czech Republic'),\n",
    "    ('DK', 'Denmark'),\n",
    "    ('DJ', 'Djibouti'),\n",
    "    ('DM', 'Dominica'),\n",
    "    ('DO', 'Dominican Republic'),\n",
    "    ('TP', 'East Timor'),\n",
    "    ('EC', 'Ecuador'),\n",
    "    ('EG', 'Egypt'),\n",
    "    ('SV', 'El Salvador'),\n",
    "    ('GQ', 'Equatorial Guinea'),\n",
    "    ('ER', 'Eritrea'),\n",
    "    ('EE', 'Estonia'),\n",
    "    ('ET', 'Ethiopia'),\n",
    "    ('FK', 'Falkland Islands (Malvinas)'),\n",
    "    ('FO', 'Faroe Islands'),\n",
    "    ('FJ', 'Fiji'),\n",
    "    ('FI', 'Finland'),\n",
    "    ('FR', 'France'),\n",
    "    ('GF', 'French Guiana'),\n",
    "    ('PF', 'French Polynesia'),\n",
    "    ('TF', 'French S. Territories'),\n",
    "    ('GA', 'Gabon'),\n",
    "    ('GM', 'Gambia'),\n",
    "    ('GE', 'Georgia'),\n",
    "    ('DE', 'Germany'),\n",
    "    ('GH', 'Ghana'),\n",
    "    ('GI', 'Gibraltar'),\n",
    "    ('GR', 'Greece'),\n",
    "    ('GL', 'Greenland'),\n",
    "    ('GD', 'Grenada'),\n",
    "    ('GP', 'Guadeloupe'),\n",
    "    ('GU', 'Guam'),\n",
    "    ('GT', 'Guatemala'),\n",
    "    ('GN', 'Guinea'),\n",
    "    ('GW', 'Guinea-bissau'),\n",
    "    ('GY', 'Guyana'),\n",
    "    ('HT', 'Haiti'),\n",
    "    ('HN', 'Honduras'),\n",
    "    ('HK', 'Hong Kong'),\n",
    "    ('HU', 'Hungary'),\n",
    "    ('IS', 'Iceland'),\n",
    "    ('IN', 'India'),\n",
    "    ('ID', 'Indonesia'),\n",
    "    ('IR', 'Iran'),\n",
    "    ('IQ', 'Iraq'),\n",
    "    ('IE', 'Ireland'),\n",
    "    ('IL', 'Israel'),\n",
    "    ('IT', 'Italy'),\n",
    "    ('JM', 'Jamaica'),\n",
    "    ('JP', 'Japan'),\n",
    "    ('JO', 'Jordan'),\n",
    "    ('KZ', 'Kazakhstan'),\n",
    "    ('KE', 'Kenya'),\n",
    "    ('KI', 'Kiribati'),\n",
    "    ('KP', 'Korea (North)'),\n",
    "    ('KR', 'Korea (South)'),\n",
    "    ('KW', 'Kuwait'),\n",
    "    ('KG', 'Kyrgyzstan'),\n",
    "    ('LA', 'Laos'),\n",
    "    ('LV', 'Latvia'),\n",
    "    ('LB', 'Lebanon'),\n",
    "    ('LS', 'Lesotho'),\n",
    "    ('LR', 'Liberia'),\n",
    "    ('LY', 'Libya'),\n",
    "    ('LI', 'Liechtenstein'),\n",
    "    ('LT', 'Lithuania'),\n",
    "    ('LU', 'Luxembourg'),\n",
    "    ('MO', 'Macau'),\n",
    "    ('MK', 'Macedonia'),\n",
    "    ('MG', 'Madagascar'),\n",
    "    ('MW', 'Malawi'),\n",
    "    ('MY', 'Malaysia'),\n",
    "    ('MV', 'Maldives'),\n",
    "    ('ML', 'Mali'),\n",
    "    ('MT', 'Malta'),\n",
    "    ('MH', 'Marshall Islands'),\n",
    "    ('MQ', 'Martinique'),\n",
    "    ('MR', 'Mauritania'),\n",
    "    ('MU', 'Mauritius'),\n",
    "    ('YT', 'Mayotte'),\n",
    "    ('MX', 'Mexico'),\n",
    "    ('FM', 'Micronesia'),\n",
    "    ('MD', 'Moldova'),\n",
    "    ('MC', 'Monaco'),\n",
    "    ('MN', 'Mongolia'),\n",
    "    ('MS', 'Montserrat'),\n",
    "    ('MA', 'Morocco'),\n",
    "    ('MZ', 'Mozambique'),\n",
    "    ('MM', 'Myanmar'),\n",
    "    ('NA', 'Namibia'),\n",
    "    ('NR', 'Nauru'),\n",
    "    ('NP', 'Nepal'),\n",
    "    ('NL', 'Netherlands'),\n",
    "    ('AN', 'Netherlands Antilles'),\n",
    "    ('NC', 'New Caledonia'),\n",
    "    ('NZ', 'New Zealand'),\n",
    "    ('NI', 'Nicaragua'),\n",
    "    ('NE', 'Niger'),\n",
    "    ('NG', 'Nigeria'),\n",
    "    ('NU', 'Niue'),\n",
    "    ('NF', 'Norfolk Island'),\n",
    "    ('MP', 'Northern Mariana Islands'),\n",
    "    ('NO', 'Norway'),\n",
    "    ('OM', 'Oman'),\n",
    "    ('PK', 'Pakistan'),\n",
    "    ('PW', 'Palau'),\n",
    "    ('PA', 'Panama'),\n",
    "    ('PG', 'Papua New Guinea'),\n",
    "    ('PY', 'Paraguay'),\n",
    "    ('PE', 'Peru'),\n",
    "    ('PH', 'Philippines'),\n",
    "    ('PN', 'Pitcairn'),\n",
    "    ('PL', 'Poland'),\n",
    "    ('PT', 'Portugal'),\n",
    "    ('PR', 'Puerto Rico'),\n",
    "    ('QA', 'Qatar'),\n",
    "    ('RE', 'Reunion'),\n",
    "    ('RO', 'Romania'),\n",
    "    ('RU', 'Russian Federation'),\n",
    "    ('RW', 'Rwanda'),\n",
    "    ('KN', 'Saint Kitts And Nevis'),\n",
    "    ('LC', 'Saint Lucia'),\n",
    "    ('VC', 'St Vincent/Grenadines'),\n",
    "    ('WS', 'Samoa'),\n",
    "    ('SM', 'San Marino'),\n",
    "    ('ST', 'Sao Tome'),\n",
    "    ('SA', 'Saudi Arabia'),\n",
    "    ('SN', 'Senegal'),\n",
    "    ('SC', 'Seychelles'),\n",
    "    ('SL', 'Sierra Leone'),\n",
    "    ('SG', 'Singapore'),\n",
    "    ('SK', 'Slovakia'),\n",
    "    ('SI', 'Slovenia'),\n",
    "    ('SB', 'Solomon Islands'),\n",
    "    ('SO', 'Somalia'),\n",
    "    ('ZA', 'South Africa'),\n",
    "    ('ES', 'Spain'),\n",
    "    ('LK', 'Sri Lanka'),\n",
    "    ('SH', 'St. Helena'),\n",
    "    ('PM', 'St.Pierre'),\n",
    "    ('SD', 'Sudan'),\n",
    "    ('SR', 'Suriname'),\n",
    "    ('SZ', 'Swaziland'),\n",
    "    ('SE', 'Sweden'),\n",
    "    ('CH', 'Switzerland'),\n",
    "    ('SY', 'Syrian Arab Republic'),\n",
    "    ('TW', 'Taiwan'),\n",
    "    ('TJ', 'Tajikistan'),\n",
    "    ('TZ', 'Tanzania'),\n",
    "    ('TH', 'Thailand'),\n",
    "    ('TG', 'Togo'),\n",
    "    ('TK', 'Tokelau'),\n",
    "    ('TO', 'Tonga'),\n",
    "    ('TT', 'Trinidad And Tobago'),\n",
    "    ('TN', 'Tunisia'),\n",
    "    ('TR', 'Turkey'),\n",
    "    ('TM', 'Turkmenistan'),\n",
    "    ('TV', 'Tuvalu'),\n",
    "    ('UG', 'Uganda'),\n",
    "    ('UA', 'Ukraine'),\n",
    "    ('AE', 'United Arab Emirates'),\n",
    "    ('UK', 'United Kingdom'),\n",
    "    ('UY', 'Uruguay'),\n",
    "    ('UZ', 'Uzbekistan'),\n",
    "    ('VU', 'Vanuatu'),\n",
    "    ('VA', 'Vatican City State'),\n",
    "    ('VE', 'Venezuela'),\n",
    "    ('VN', 'Viet Nam'),\n",
    "    ('VG', 'Virgin Islands (British)'),\n",
    "    ('VI', 'Virgin Islands (U.S.)'),\n",
    "    ('EH', 'Western Sahara'),\n",
    "    ('YE', 'Yemen'),\n",
    "    ('YU', 'Yugoslavia'),\n",
    "    ('ZR', 'Zaire'),\n",
    "    ('ZM', 'Zambia'),\n",
    "    ('ZW', 'Zimbabwe')\n",
    "]\n",
    "\n",
    "validCountries = {name for code, name in Country}\n",
    "validRatings = {\"G\", \"PG\", \"PG-13\", \"R\", \"NC-17\", \"TV-Y\", \"TV-Y7\", \"TV-G\", \"TV-PG\", \"TV-14\", \"TV-MA\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checker Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countryError = netflixData[netflixData['country'].notna() & ~netflixData['country'].isin(validCountries)]\n",
    "ratingError = netflixData[netflixData['rating'].notna() & ~netflixData['rating'].isin(validRatings)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Findings\n",
    "\n",
    "There are many country lookup errors in the data because my check doesn't account for multiple values inside the country column. There are still errors with the wrong stuff being present in the wrong columns in the louis CK ones as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nCountry error: \\n\", countryError[['title', 'show_id', 'country']].head(5))\n",
    "print(\"\\nRating error: \\n\", ratingError[['title', 'show_id', 'rating']].head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exact Duplicate Errors\n",
    "Exact duplicates occur when multiple rows in the dataset contain the exact same values \n",
    "for all attributes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_subset = ['title', 'show_id', 'country']  # Columns to check for exact duplicates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checker Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exactDuplicates = netflixData[netflixData.duplicated(subset=duplicate_subset)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Findings\n",
    "\n",
    "There are no exact duplicates in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nExact Duplicate Errors: \\n\", exactDuplicates[duplicate_subset].head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Near Duplicate Errors\n",
    "\n",
    "Near duplicates are rows that are very similar but have slight differences. This may \n",
    "occur due to typos, inconsistent data formatting, or variations in missing values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I decided to assume that the titles were correct and am using it as a key to look for near duplicates in comparison\n",
    "#i.e. duplicates where title matches but other columns differ\n",
    "titleCol = 'title'\n",
    "comparisonCols = ['show_id', 'country', 'rating', 'director', 'cast', 'release_year']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checker Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearDuplicates = netflixData[netflixData.duplicated(subset=[titleCol], keep=False)]  # Find rows with duplicate titles\n",
    "\n",
    "nearDuplicateErrors = nearDuplicates[nearDuplicates.apply(\n",
    "    lambda row: any(row[comparisonCols] != nearDuplicates[comparisonCols].iloc[0]), #look for differences in comparison columns\n",
    "    axis=1)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Findings\n",
    "\n",
    "There are no near duplicates with the same title but different values in the other columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nNear Duplicate Errors: \\n\", nearDuplicateErrors[comparisonCols + [titleCol]].head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputation\n",
    "\n",
    "#### Test #1\n",
    "\n",
    "- a) Funding Rounds \n",
    "- b) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
